{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#clear directory \n",
    "!rm -r ./YahooNews/YahooNewsQualityDataset-v0.8\n",
    "!rm ./Kaggle/fake.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import zipfile\n",
    "zip_ref1 = zipfile.ZipFile('./YahooNews/YahooNewsQualityDataset-v0.8.zip', 'r')\n",
    "zip_ref1.extractall('./YahooNews/')\n",
    "zip_ref1.close()\n",
    "\n",
    "\n",
    "zip_ref2 = zipfile.ZipFile('./Kaggle/fake-news.zip', 'r')\n",
    "zip_ref2.extractall('./Kaggle/')\n",
    "zip_ref2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotators.xlsx  excel_dataset.py  news.tsv\n",
      "dataset\t\t methodology\t   sentences.tsv\n",
      "fake-news.zip  fake.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./YahooNews/YahooNewsQualityDataset-v0.8\n",
    "!ls ./Kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "folder = 'YahooNews/YahooNewsQualityDataset-v0.8/'\n",
    "news_tsv_folder = os.path.join(os.getcwd(),folder+'dataset/tsvFiles/withText-body/')\n",
    "sentences_tsv_folder = os.path.join(os.getcwd(),folder+'dataset/tsvFiles/withText-sentences/')\n",
    "\n",
    "news_csv = os.path.join(os.getcwd(),'news.csv')\n",
    "sentences_csv = os.path.join(os.getcwd(),'sentences.csv')\n",
    "\n",
    "news_csv_out = open(news_csv, 'w')\n",
    "sentences_csv_out = open(sentences_csv, 'w')\n",
    "\n",
    "# write headers\n",
    "news_csv_out.write('id\\tnews article name\\tnews article\\tFluency\\tConciseness\\tDescriptiveness\\tNovelty\\tCompleteness\\t')\n",
    "news_csv_out.write('Referencing\\tFormality\\tRichness\\tAttractiveness\\tTechnicality\\tPopularity\\tSubjectivity\\t')\n",
    "news_csv_out.write('Positive Emotion\\tNegative Emotion\\tQuality\\tAnnotatorsConfidenceScore\\n')\n",
    "\n",
    "news_article_names = {}\n",
    "\n",
    "curr_id = 1 \n",
    "for filename in os.listdir(news_tsv_folder):\n",
    "\tcurr_file = open(os.path.join(news_tsv_folder, filename), 'r')\n",
    "\tline = curr_file.readline().replace('\\n','').replace('\\r','')\n",
    "\tline = line.split('\\t')\n",
    "\tnews_article_name = filename.replace('-sentences.txt','').replace('_sentences.txt','').replace('-body.txt','').replace('_body.txt','')\n",
    "\tnews_article_names[news_article_name] = curr_id\n",
    "\tnews_article = line[0]\n",
    "\tFluency = line[1]\n",
    "\tConciseness = line[2]\n",
    "\tDescriptiveness = line[3]\n",
    "\tNovelty = line[4]\n",
    "\tCompleteness = line[5]\n",
    "\tReferencing = line[6]\n",
    "\tFormality = line[7]\n",
    "\tRichness = line[8]\n",
    "\tAttractiveness = line[9]\n",
    "\tTechnicality = line[10]\n",
    "\tPopularity = line[11]\n",
    "\tSubjectivity = line[12]\n",
    "\tPositive_Emotion = line[13]\n",
    "\tNegative_Emotion = line[14]\n",
    "\tQuality = line[15]\n",
    "\tif len(line) == 17:\n",
    "\t\tAnnotatorsConfidenceScore = line[16]\n",
    "\telse:\n",
    "\t\tAnnotatorsConfidenceScore = ''\n",
    "\tnews_csv_out.write(str(curr_id)+'\\t'+news_article_name+'\\t'+news_article+'\\t'+Fluency+'\\t'+Conciseness+'\\t'+Descriptiveness+'\\t'+Novelty+'\\t'+Completeness+'\\t')\n",
    "\tnews_csv_out.write(Referencing+'\\t'+Formality+'\\t'+Richness+'\\t'+Attractiveness+'\\t'+Technicality+'\\t')\n",
    "\tnews_csv_out.write(Popularity+'\\t'+Subjectivity+'\\t'+Positive_Emotion+'\\t'+Negative_Emotion+'\\t'+Quality+'\\t'+AnnotatorsConfidenceScore+'\\n')\n",
    "\tcurr_id = curr_id + 1\n",
    "\tcurr_file.close()\n",
    "news_csv_out.close()\n",
    "\n",
    "# write headers\n",
    "sentences_csv_out.write('id\\tnews article name\\tSentence\\tSubjectivity\\tPositivity\\tNegativity\\t')\n",
    "sentences_csv_out.write('Ignore sentence (I) or sentence Splitting issue (S)\\tAnnotatorsConfidenceScore\\n')\n",
    "for filename in os.listdir(sentences_tsv_folder):\n",
    "\tcurr_file = open(os.path.join(sentences_tsv_folder, filename), 'r')\n",
    "\tnews_article_name = filename.replace('-sentences.txt','').replace('_sentences.txt','').replace('-body.txt','').replace('_body.txt','')\n",
    "\tcurr_id = news_article_names[news_article_name]\n",
    "\twhile 1:\t\n",
    "\t\tsentence = curr_file.readline()\n",
    "\t\tif not sentence:break\n",
    "\t\tline = sentence.replace('\\n','').replace('\\r','').split('\\t')\n",
    "\t\tif len(line) == 1:break\n",
    "\t\tnews_article = line[0]\n",
    "\t\tsentence = line[1]\n",
    "\t\tsubjectivity = line[2]\n",
    "\t\tpositivity = line[3]\n",
    "\t\tnegativity = line[4]\n",
    "\t\tif len(line) == 6:\n",
    "\t\t\tI_S = line[5]\n",
    "\t\telse:\n",
    "\t\t\tI_S = ''\n",
    "\t\tif len(line) == 7:\n",
    "\t\t\tannotatorsConfidenceScore = line[6]\n",
    "\t\telse:\n",
    "\t\t\tannotatorsConfidenceScore = ''\n",
    "\t\tsentences_csv_out.write(str(curr_id)+'\\t'+news_article_name+'\\t'+news_article+'\\t'+sentence+'\\t'+subjectivity+'\\t')\n",
    "\t\tsentences_csv_out.write(positivity+'\\t'+negativity+'\\t'+I_S+'\\t'+annotatorsConfidenceScore+'\\n')\n",
    "\tcurr_file.close()\n",
    "sentences_csv_out.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "header = []\n",
    "articleData = []\n",
    "with open('news.csv', 'rb') as f:\n",
    "    for line in f:\n",
    "        if len(header) == 0:\n",
    "            header = line.split('\\t')\n",
    "        else:\n",
    "            articleData.append(line.split('\\t'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658 19\n",
      "['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns = len(header)\n",
    "rows = len(articleData)\n",
    "print rows, columns\n",
    "print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['346', 'park-defends-refusal-wolves-184423303', \"BOULDER, Colo. (AP) \\xe2\\x80\\x94 The National Park Service acted properly when it ruled out using wolves to control the elk population in Rocky Mountain National Park, government lawyers argued Thursday before a federal appeals court.The government also defended the use of trained volunteers to help Park Service employees shoot and kill excess elk, saying it didn't violate a hunting ban in national parks.In a hearing before the 10th U.S. Circuit Court of Appeals, a law student representing the wildlife advocacy group WildEarth Guardians argued the Park Service did not give enough consideration to the wolf option and rejected it without giving the public a chance to comment.The group also said letting volunteers shoot elk instead of limiting the shooting to Park Service employees was tantamount to hunting.WildEarth Guardians sued the Park Service in 2008, asking a Denver federal judge to overturn the park's elk-thinning policy. The judge upheld the policy last year, and WildEarth Guardians appealed to the 10th Circuit.The appeals court normally meets in Denver but heard this case at the University of Colorado Law School in Boulder as part of an outreach program. The judges did not say when they would rule.Rocky Mountain National Park sometimes has so many elk that they overgraze the vegetation, leaving other animals without enough food and habitat. Few natural predators are left there, and hunting is prohibited, so little remains to keep the elk population in check.The park launched a 20-year program in 2008 to thin the herd by having park employees and trained volunteers under park supervision periodically shoot and kill elk. The program also includes fences to protect vegetation from elk and redistributing some of the animals.Officials said reintroducing wolves to control elk numbers was infeasible. They cited a lack of support from other agencies, safety concerns of people who live nearby, expected conflicts between wolves and humans and the amount of attention that a wolf population would require of park officials.Park spokeswoman Kyle Patterson said 131 elk have been killed in the culling program during since 2008.The current size of the herd in the park's lower elevations is 600 to 800, which is within the target range set by the program, so no elk were killed last winter.No decision has been made on whether or how many elk will be killed this coming winter.Wolves disappeared from much of the West after decades of hunting and government-backed extermination. They were re-introduced in Yellowstone National Park in Wyoming in 1995, and some advocates have argued for bringing them back elsewhere.___Follow Dan Elliott at http://twitter.com/DanElliottAP___Online:National Park Service fact sheet: http://1.usa.gov/UllcuKWildEarth Guardians: http://bit.ly/T94CDm\", '4', '3', '3', '3', '3', '3', '2', '3', '3', '2', '3', '2', '1', '2', '3', '4\\n']\n"
     ]
    }
   ],
   "source": [
    "print articleData[345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[543, 228, 168, 212, 188, 411, 589, 162, 431, 24, 461, 257, 114, 406, 183, 286, 15, 549, 467, 400, 300, 54, 155, 312, 546, 417, 20, 653, 377, 140, 415, 116, 613, 618, 302, 107, 354, 455, 402, 205, 1, 75, 565, 47, 611, 207, 147, 522, 654, 223, 382, 85, 39, 511, 345, 190, 252, 98, 440, 640, 51, 102, 622, 365, 165, 358, 476, 138, 595, 305, 333, 258, 206, 109, 238, 442, 545, 454, 515, 97, 5, 495, 607, 319, 324, 557, 94, 204, 378, 224, 636, 389, 344, 119, 584, 3, 36, 221, 608, 630, 564, 396, 142, 253, 185, 156, 370, 208, 213, 433, 410, 149, 176, 413, 483, 309, 633, 35, 453, 626, 397, 303, 644, 251, 349, 484, 313, 124, 525, 458, 254]\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "rowid = range(0, rows)\n",
    "shuffle(rowid)\n",
    "trainid = []\n",
    "testid = []\n",
    "ratio = 0.8\n",
    "for i in range(0, rows):\n",
    "    if i < rows * ratio:\n",
    "        trainid.append(rowid[i])\n",
    "    else:\n",
    "        testid.append(rowid[i])\n",
    "\n",
    "print testid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data from yahoo dataset\n",
    "def load_yahoo_data(label_used):\n",
    "    header = []\n",
    "    articleData = []\n",
    "    with open('./news.csv', 'rb') as f:\n",
    "        for line in f:\n",
    "            if len(header) == 0:\n",
    "                header = line.split('\\t')\n",
    "            else:\n",
    "                articleData.append(line.split('\\t'))\n",
    "    columns = len(header)\n",
    "    rows = len(articleData)\n",
    "    print 'Loaded rows: ', rows,'columns: ', columns\n",
    "    print 'Headers: ', header\n",
    "    print 'Using label: ', label_used\n",
    "    #print 'sample text: ', articleData[0][header.index('news article')]\n",
    "    #print 'sample label: ', articleData[0][header.index(label_used)]\n",
    "    \n",
    "    texts = []\n",
    "    targets = []\n",
    "    for i in range(0, rows):\n",
    "        labelStr = articleData[i][header.index(label_used)]\n",
    "        if labelStr != '':\n",
    "            texts.append(articleData[i][header.index('news article')])\n",
    "            target = int(labelStr)\n",
    "            labels = [[0,1]]\n",
    "            if target <= 3:\n",
    "                labels = [[1,0]]\n",
    "            targets.append(labels)\n",
    "    y = np.concatenate(targets, 0)\n",
    "    return (texts, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Quality\n"
     ]
    }
   ],
   "source": [
    "(tests, y) = load_yahoo_data('Quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data from facebook dataset\n",
    "def load_facebook_data():\n",
    "    articleData = []\n",
    "    labelStrs = []\n",
    "    with open('./text_and_labels.tsv', 'rb') as f:\n",
    "        for line in f:\n",
    "            articleData.append(line.split('\\t'))\n",
    "    columns = 2\n",
    "    rows = len(articleData)\n",
    "    print 'Loaded rows: ', rows,'columns: ', columns\n",
    "    \n",
    "    texts = []\n",
    "    targets = []\n",
    "    for i in range(0, rows):\n",
    "        labelStr = articleData[i][1]\n",
    "        if labelStr != '':\n",
    "            texts.append(articleData[i][0])\n",
    "            if labelStr not in labelStrs:\n",
    "                labelStrs.append(labelStr)\n",
    "                \n",
    "            if labelStr.startswith('mostly true'):\n",
    "                target = 4\n",
    "            if labelStr.startswith('mixture of true and false'):\n",
    "                target = 0\n",
    "            if labelStr.startswith('no factual content'):\n",
    "                target = 0;\n",
    "            if labelStr.startswith('mostly false'):\n",
    "                target = 0;\n",
    "         \n",
    "            labels = [1]\n",
    "            if target <= 3:\n",
    "                labels = [0]\n",
    "            targets.append(labels)\n",
    "    y = np.concatenate(targets, 0)\n",
    "    return (texts, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows:  159 columns:  2\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "(texts, targets) = load_facebook_data()\n",
    "print targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "Ivanka Trump met privately with House Speaker Paul Ryan, R-Wisconsin, Monday in New York City, sources confirmed to ABC News.  Trump, who requested the meeting, attended Ryan's speech at the Economic Club of New York before the two had a scheduled meeting.  House Speaker Paul Ryan Urges GOP Unity Behind Donald Trump Paul Ryan Criticizes Vladimir Putin Amid Trump's Praise for Russian Leader Ryan shared some of his experiences from the 2012 presidential campaign trail and Trump provided Ryan with an update on her father's presidential campaign, according to a source.  Ryan has not crossed paths with Trump or his family since the Republican National Convention. He has been running a parallel election-year campaign touting the House GOP \"Better Way\" policy agenda and raising money for Republicans in the House and Senate, setting fundraising records.  Last week, he suggested Trump should release his tax returns.  Ivanka Trump, who is one of her father's closest confidantes, has kept in touch with Hill Republicans throughout the presidential campaign on policy issues.  She also joined her father in Washington, D.C. for his meetings with House and Senate Republicans in early July.  \"She was good,\" Rep. Peter King, R-New York, told reporters at the time.  ABC's John Santucci contributed to this report.\n"
     ]
    }
   ],
   "source": [
    "print np.size(texts)\n",
    "print texts[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Formality\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Formality\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492410110\n",
      "\n",
      "2017-04-17T06:22:01.338031: step 1, loss 2.84736, acc 0.58\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1]))\n",
      "2017-04-17T06:22:10.933225: step 2, loss 2.57804, acc 0.51\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "       0, 1, 0, 1, 0, 1, 0, 1]))\n",
      "2017-04-17T06:22:20.225646: step 3, loss 2.46455, acc 0.6\n",
      "('predictions for this batch:', array([0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1]))\n",
      "2017-04-17T06:22:29.586964: step 4, loss 2.57753, acc 0.56\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "       1, 0, 1, 0, 0, 1, 0, 0]))\n",
      "2017-04-17T06:22:38.942125: step 5, loss 3.10657, acc 0.52\n",
      "('predictions for this batch:', array([0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 0, 0]))\n",
      "2017-04-17T06:22:47.456852: step 6, loss 3.17086, acc 0.44086\n",
      "('predictions for this batch:', array([0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:22:49.498728: step 6, loss 0.951451, acc 0.476923\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410110/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:22:59.274659: step 7, loss 2.06058, acc 0.6\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 1, 0]))\n",
      "2017-04-17T06:23:08.480435: step 8, loss 3.09598, acc 0.52\n",
      "('predictions for this batch:', array([0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "       1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 1]))\n",
      "2017-04-17T06:23:17.797655: step 9, loss 2.78032, acc 0.53\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 1]))\n",
      "2017-04-17T06:23:28.067426: step 10, loss 2.76356, acc 0.49\n",
      "('predictions for this batch:', array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:23:37.557874: step 11, loss 2.08848, acc 0.6\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1]))\n",
      "2017-04-17T06:23:46.350499: step 12, loss 3.14448, acc 0.505376\n",
      "('predictions for this batch:', array([1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:23:48.400395: step 12, loss 0.841468, acc 0.476923\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410110/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Formality' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 90M\r\n",
      "-rw-r--r-- 1 root root  252 Apr 17 06:23 checkpoint\r\n",
      "-rw-r--r-- 1 root root  45M Apr 17 06:23 model-12.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root 1.1K Apr 17 06:23 model-12.index\r\n",
      "-rw-r--r-- 1 root root 117K Apr 17 06:23 model-12.meta\r\n",
      "-rw-r--r-- 1 root root  45M Apr 17 06:22 model-6.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root 1.1K Apr 17 06:22 model-6.index\r\n",
      "-rw-r--r-- 1 root root 117K Apr 17 06:22 model-6.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /notebooks/Project/runs/1492410110/checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_DIR=/notebooks/Project/runs/1492410110/checkpoints\n",
      "EVAL_TRAIN=False\n",
      "LABEL_USED=Fluency\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loaded rows:  159 columns:  2\n",
      "Vocabulary Size: 28958\n",
      "Raw text Size: 6908\n",
      "Transformed text Size: 2381\n",
      "\n",
      "Evaluating using directory...\n",
      "\n",
      "/notebooks/Project/runs/1492410110/checkpoints\n",
      "('Loading...', '/notebooks/Project/runs/1492410110/checkpoints/model-12.meta')\n",
      "('checkpoint_file', u'/notebooks/Project/runs/1492410110/checkpoints/model-12')\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[ 0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.\n",
      "  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.  1.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  1.  1.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.\n",
      "  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.]\n",
      "Total number of test examples: 159\n",
      "Accuracy: 0.528302\n",
      "Saving evaluation to /notebooks/Project/runs/1492410110/checkpoints/../prediction.csv\n",
      "Saving evaluation to /notebooks/Project/runs/1492410110/checkpoints/../prediction.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/eval.py --checkpoint_dir '/notebooks/Project/runs/1492410110/checkpoints' --batch_size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Fluency\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Fluency\n",
      "Vocabulary Size: 28943\n",
      "Train/Dev split: 592/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492410421\n",
      "\n",
      "2017-04-17T06:27:12.278871: step 1, loss 2.53013, acc 0.63\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:27:22.074874: step 2, loss 3.00498, acc 0.5\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1]))\n",
      "2017-04-17T06:27:32.198588: step 3, loss 2.75052, acc 0.55\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 0, 1, 0, 0, 1, 1]))\n",
      "2017-04-17T06:27:42.214068: step 4, loss 2.3718, acc 0.6\n",
      "('predictions for this batch:', array([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0]))\n",
      "2017-04-17T06:27:51.540599: step 5, loss 2.32073, acc 0.67\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 0, 1]))\n",
      "2017-04-17T06:28:00.911196: step 6, loss 2.56019, acc 0.608696\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:28:03.048789: step 6, loss 2.05633, acc 0.676923\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410421/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:28:14.204262: step 7, loss 2.5427, acc 0.68\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:28:24.979890: step 8, loss 1.6932, acc 0.68\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:28:35.362350: step 9, loss 2.03619, acc 0.65\n",
      "('predictions for this batch:', array([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:28:45.187701: step 10, loss 1.59522, acc 0.73\n",
      "('predictions for this batch:', array([1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1]))\n",
      "2017-04-17T06:28:55.115895: step 11, loss 1.70032, acc 0.64\n",
      "('predictions for this batch:', array([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:29:04.391887: step 12, loss 2.12715, acc 0.608696\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:29:06.699222: step 12, loss 1.39061, acc 0.676923\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410421/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Fluency' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_DIR=/notebooks/Project/runs/1492410421/checkpoints\n",
      "EVAL_TRAIN=False\n",
      "LABEL_USED=Fluency\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loaded rows:  159 columns:  2\n",
      "Vocabulary Size: 28943\n",
      "Raw text Size: 6908\n",
      "Transformed text Size: 2381\n",
      "\n",
      "Evaluating using directory...\n",
      "\n",
      "/notebooks/Project/runs/1492410421/checkpoints\n",
      "('Loading...', '/notebooks/Project/runs/1492410421/checkpoints/model-12.meta')\n",
      "('checkpoint_file', u'/notebooks/Project/runs/1492410421/checkpoints/model-12')\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "Total number of test examples: 159\n",
      "Accuracy: 0.408805\n",
      "Saving evaluation to /notebooks/Project/runs/1492410421/checkpoints/../prediction.csv\n",
      "Saving evaluation to /notebooks/Project/runs/1492410421/checkpoints/../prediction.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/eval.py --checkpoint_dir '/notebooks/Project/runs/1492410421/checkpoints' --batch_size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Conciseness\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Conciseness\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492410549\n",
      "\n",
      "2017-04-17T06:29:20.993288: step 1, loss 3.09419, acc 0.46\n",
      "('predictions for this batch:', array([0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1]))\n",
      "2017-04-17T06:29:30.998831: step 2, loss 1.73301, acc 0.65\n",
      "('predictions for this batch:', array([0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0]))\n",
      "2017-04-17T06:29:40.931554: step 3, loss 1.2316, acc 0.74\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1]))\n",
      "2017-04-17T06:29:50.913831: step 4, loss 1.56931, acc 0.78\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1]))\n",
      "2017-04-17T06:30:01.358081: step 5, loss 2.03544, acc 0.82\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:30:11.173299: step 6, loss 2.73456, acc 0.741935\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:30:13.328512: step 6, loss 2.84822, acc 0.738462\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410549/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:30:23.869821: step 7, loss 1.28432, acc 0.82\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:30:33.584748: step 8, loss 1.88916, acc 0.84\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:30:42.772380: step 9, loss 1.47532, acc 0.8\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:30:52.063025: step 10, loss 2.14322, acc 0.72\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:31:01.352918: step 11, loss 1.50066, acc 0.78\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:31:10.079096: step 12, loss 1.40938, acc 0.784946\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:31:12.201988: step 12, loss 1.51782, acc 0.738462\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410549/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Conciseness' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Descriptiveness\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Descriptiveness\n",
      "Vocabulary Size: 28944\n",
      "Train/Dev split: 592/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492410675\n",
      "\n",
      "2017-04-17T06:31:25.943830: step 1, loss 1.48566, acc 0.74\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 1, 0, 1]))\n",
      "2017-04-17T06:31:35.523456: step 2, loss 1.85485, acc 0.79\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0]))\n",
      "2017-04-17T06:31:44.886072: step 3, loss 2.60686, acc 0.79\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:31:54.169214: step 4, loss 1.79349, acc 0.76\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:32:03.507344: step 5, loss 1.83724, acc 0.73\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:32:12.092596: step 6, loss 2.06057, acc 0.663043\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:32:14.141117: step 6, loss 1.10241, acc 0.815385\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410675/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:32:23.952591: step 7, loss 1.22931, acc 0.76\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:32:33.260304: step 8, loss 1.37498, acc 0.75\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:32:42.670509: step 9, loss 1.51578, acc 0.72\n",
      "('predictions for this batch:', array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0]))\n",
      "2017-04-17T06:32:51.963449: step 10, loss 1.37092, acc 0.7\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:33:01.350299: step 11, loss 2.02034, acc 0.67\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1]))\n",
      "2017-04-17T06:33:09.870741: step 12, loss 1.89338, acc 0.782609\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:33:11.885951: step 12, loss 1.72906, acc 0.815385\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410675/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Descriptiveness' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Novelty\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Novelty\n",
      "Vocabulary Size: 28918\n",
      "Train/Dev split: 592/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492410794\n",
      "\n",
      "2017-04-17T06:33:24.997354: step 1, loss 1.18486, acc 0.73\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0]))\n",
      "2017-04-17T06:33:34.407424: step 2, loss 1.34725, acc 0.84\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:33:43.827064: step 3, loss 2.07723, acc 0.78\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:33:53.203109: step 4, loss 2.48833, acc 0.76\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1]))\n",
      "2017-04-17T06:34:02.501833: step 5, loss 2.45159, acc 0.71\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:34:11.188117: step 6, loss 1.8063, acc 0.804348\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:34:13.248433: step 6, loss 2.19987, acc 0.692308\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410794/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:34:23.020627: step 7, loss 1.63772, acc 0.74\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:34:32.387017: step 8, loss 1.20753, acc 0.73\n",
      "('predictions for this batch:', array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 1, 0, 1, 1]))\n",
      "2017-04-17T06:34:41.815346: step 9, loss 1.46131, acc 0.74\n",
      "('predictions for this batch:', array([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:34:51.229114: step 10, loss 1.27285, acc 0.72\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1]))\n",
      "2017-04-17T06:35:00.504461: step 11, loss 2.07241, acc 0.64\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:35:09.179030: step 12, loss 2.12499, acc 0.630435\n",
      "('predictions for this batch:', array([0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:35:11.229946: step 12, loss 1.85706, acc 0.692308\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410794/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Novelty' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Completeness\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Completeness\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492410913\n",
      "\n",
      "2017-04-17T06:35:24.326727: step 1, loss 4.44094, acc 0.72\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:35:33.733203: step 2, loss 5.32519, acc 0.62\n",
      "('predictions for this batch:', array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:35:43.010667: step 3, loss 3.90362, acc 0.64\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:35:52.302495: step 4, loss 2.50846, acc 0.66\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1]))\n",
      "2017-04-17T06:36:01.638331: step 5, loss 2.47639, acc 0.62\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1]))\n",
      "2017-04-17T06:36:10.391877: step 6, loss 2.35865, acc 0.591398\n",
      "('predictions for this batch:', array([1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:36:12.466587: step 6, loss 0.797531, acc 0.507692\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410913/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:36:22.104303: step 7, loss 2.07782, acc 0.61\n",
      "('predictions for this batch:', array([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0]))\n",
      "2017-04-17T06:36:31.577463: step 8, loss 3.40607, acc 0.48\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "       0, 0, 1, 0, 1, 0, 0, 1]))\n",
      "2017-04-17T06:36:41.151094: step 9, loss 2.86323, acc 0.48\n",
      "('predictions for this batch:', array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "       0, 1, 0, 0, 0, 0, 1, 1]))\n",
      "2017-04-17T06:36:50.322205: step 10, loss 2.78222, acc 0.52\n",
      "('predictions for this batch:', array([1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 0, 1]))\n",
      "2017-04-17T06:36:59.443340: step 11, loss 1.83327, acc 0.62\n",
      "('predictions for this batch:', array([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 1]))\n",
      "2017-04-17T06:37:07.982220: step 12, loss 1.8557, acc 0.569892\n",
      "('predictions for this batch:', array([0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:37:10.070690: step 12, loss 1.26534, acc 0.661538\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492410913/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Completeness' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Referencing\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Referencing\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492411033\n",
      "\n",
      "2017-04-17T06:37:24.137139: step 1, loss 4.48194, acc 0.44\n",
      "('predictions for this batch:', array([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:37:33.453857: step 2, loss 3.46642, acc 0.48\n",
      "('predictions for this batch:', array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "       0, 1, 1, 0, 1, 1, 1, 0]))\n",
      "2017-04-17T06:37:42.711614: step 3, loss 2.6994, acc 0.55\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:37:51.925735: step 4, loss 2.96312, acc 0.5\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "       1, 1, 0, 1, 0, 0, 1, 1]))\n",
      "2017-04-17T06:38:01.144394: step 5, loss 2.71537, acc 0.6\n",
      "('predictions for this batch:', array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 0, 0, 0, 1, 1, 1, 1]))\n",
      "2017-04-17T06:38:09.661413: step 6, loss 2.85753, acc 0.623656\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:38:11.735843: step 6, loss 2.38052, acc 0.646154\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411033/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:38:21.633230: step 7, loss 3.27898, acc 0.58\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0]))\n",
      "2017-04-17T06:38:30.934063: step 8, loss 2.46498, acc 0.52\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:38:40.216297: step 9, loss 2.39277, acc 0.61\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:38:49.378440: step 10, loss 2.11021, acc 0.63\n",
      "('predictions for this batch:', array([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1]))\n",
      "2017-04-17T06:38:58.576331: step 11, loss 2.63421, acc 0.49\n",
      "('predictions for this batch:', array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "       0, 1, 1, 0, 1, 0, 1, 1]))\n",
      "2017-04-17T06:39:07.261634: step 12, loss 2.43535, acc 0.537634\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:39:09.273704: step 12, loss 0.694764, acc 0.646154\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411033/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Referencing' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Richness\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Richness\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492411151\n",
      "\n",
      "2017-04-17T06:39:22.434152: step 1, loss 2.77307, acc 0.53\n",
      "('predictions for this batch:', array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 1, 0, 0, 0]))\n",
      "2017-04-17T06:39:31.657274: step 2, loss 2.36589, acc 0.59\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 1]))\n",
      "2017-04-17T06:39:40.943337: step 3, loss 2.15219, acc 0.61\n",
      "('predictions for this batch:', array([0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0]))\n",
      "2017-04-17T06:39:50.207537: step 4, loss 2.22466, acc 0.56\n",
      "('predictions for this batch:', array([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:39:59.467831: step 5, loss 1.7938, acc 0.65\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 0, 1, 1, 0, 0, 1]))\n",
      "2017-04-17T06:40:08.172787: step 6, loss 3.4591, acc 0.473118\n",
      "('predictions for this batch:', array([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:40:10.204689: step 6, loss 0.97126, acc 0.569231\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411151/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:40:19.737068: step 7, loss 1.56572, acc 0.65\n",
      "('predictions for this batch:', array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "       0, 1, 0, 1, 1, 1, 0, 0]))\n",
      "2017-04-17T06:40:28.885078: step 8, loss 2.12613, acc 0.61\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 0, 1]))\n",
      "2017-04-17T06:40:38.241645: step 9, loss 2.41421, acc 0.55\n",
      "('predictions for this batch:', array([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 1]))\n",
      "2017-04-17T06:40:47.812188: step 10, loss 2.95694, acc 0.42\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0]))\n",
      "2017-04-17T06:40:57.054339: step 11, loss 1.78378, acc 0.63\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 0, 1]))\n",
      "2017-04-17T06:41:05.728486: step 12, loss 2.52071, acc 0.569892\n",
      "('predictions for this batch:', array([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:41:07.745073: step 12, loss 1.09002, acc 0.584615\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411151/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Richness' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Attractiveness\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Attractiveness\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492411270\n",
      "\n",
      "2017-04-17T06:41:20.678168: step 1, loss 4.30723, acc 0.44\n",
      "('predictions for this batch:', array([0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0]))\n",
      "2017-04-17T06:41:29.899694: step 2, loss 3.68302, acc 0.36\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 0, 0]))\n",
      "2017-04-17T06:41:39.245957: step 3, loss 2.72903, acc 0.48\n",
      "('predictions for this batch:', array([0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 0]))\n",
      "2017-04-17T06:41:48.498886: step 4, loss 3.00711, acc 0.52\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "       0, 1, 0, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:41:59.192446: step 5, loss 2.47695, acc 0.68\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1]))\n",
      "2017-04-17T06:42:09.928494: step 6, loss 2.88088, acc 0.612903\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:42:14.476934: step 6, loss 2.90627, acc 0.6\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411270/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:42:25.493213: step 7, loss 2.56044, acc 0.64\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0]))\n",
      "2017-04-17T06:42:35.430741: step 8, loss 2.66748, acc 0.6\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:42:45.577309: step 9, loss 3.08307, acc 0.58\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:42:54.945044: step 10, loss 2.21247, acc 0.65\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1]))\n",
      "2017-04-17T06:43:04.259781: step 11, loss 1.99691, acc 0.68\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 0]))\n",
      "2017-04-17T06:43:12.990003: step 12, loss 1.7008, acc 0.698925\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:43:15.048107: step 12, loss 0.886295, acc 0.6\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411270/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Attractiveness' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Technicality\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Technicality\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492411398\n",
      "\n",
      "2017-04-17T06:43:28.627982: step 1, loss 5.33655, acc 0.33\n",
      "('predictions for this batch:', array([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 0, 0, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:43:37.977291: step 2, loss 2.87208, acc 0.5\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:43:47.201510: step 3, loss 3.17918, acc 0.47\n",
      "('predictions for this batch:', array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 1, 0]))\n",
      "2017-04-17T06:43:56.533739: step 4, loss 2.8115, acc 0.6\n",
      "('predictions for this batch:', array([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0]))\n",
      "2017-04-17T06:44:05.702047: step 5, loss 3.12117, acc 0.65\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:44:14.357541: step 6, loss 2.66714, acc 0.709677\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:44:16.410851: step 6, loss 3.5694, acc 0.584615\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411398/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:44:26.306971: step 7, loss 2.8417, acc 0.72\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:44:36.297613: step 8, loss 2.57124, acc 0.73\n",
      "('predictions for this batch:', array([0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:44:46.304643: step 9, loss 3.00081, acc 0.62\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:44:56.509608: step 10, loss 1.89208, acc 0.63\n",
      "('predictions for this batch:', array([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       1, 0, 0, 1, 1, 0, 0, 0]))\n",
      "2017-04-17T06:45:05.860378: step 11, loss 2.48522, acc 0.56\n",
      "('predictions for this batch:', array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 1, 0, 0]))\n",
      "2017-04-17T06:45:14.541477: step 12, loss 1.81521, acc 0.688172\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:45:16.750554: step 12, loss 1.30002, acc 0.584615\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411398/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Technicality' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Popularity\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Popularity\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492411519\n",
      "\n",
      "2017-04-17T06:45:30.718865: step 1, loss 3.32802, acc 0.63\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1]))\n",
      "2017-04-17T06:45:40.233245: step 2, loss 2.08974, acc 0.58\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 1]))\n",
      "2017-04-17T06:45:49.705234: step 3, loss 2.11719, acc 0.61\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:45:59.678918: step 4, loss 2.43719, acc 0.56\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 1, 1, 1, 0]))\n",
      "2017-04-17T06:46:09.727023: step 5, loss 3.07193, acc 0.5\n",
      "('predictions for this batch:', array([0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0]))\n",
      "2017-04-17T06:46:18.849567: step 6, loss 2.47278, acc 0.505376\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:46:21.169302: step 6, loss 0.877678, acc 0.492308\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411519/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:46:31.929312: step 7, loss 2.27577, acc 0.58\n",
      "('predictions for this batch:', array([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 1, 0]))\n",
      "2017-04-17T06:46:42.303783: step 8, loss 2.51119, acc 0.52\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1]))\n",
      "2017-04-17T06:46:52.352984: step 9, loss 2.12267, acc 0.55\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1]))\n",
      "2017-04-17T06:47:02.540881: step 10, loss 1.64809, acc 0.65\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:47:13.224190: step 11, loss 2.53449, acc 0.58\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0]))\n",
      "2017-04-17T06:47:22.131601: step 12, loss 2.41095, acc 0.602151\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:47:24.263889: step 12, loss 2.60301, acc 0.523077\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411519/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Popularity' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Subjectivity\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Subjectivity\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492411646\n",
      "\n",
      "2017-04-17T06:47:37.647763: step 1, loss 6.6036, acc 0.29\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:47:47.134361: step 2, loss 3.28798, acc 0.47\n",
      "('predictions for this batch:', array([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "       0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 1, 0]))\n",
      "2017-04-17T06:47:56.558573: step 3, loss 2.99109, acc 0.48\n",
      "('predictions for this batch:', array([1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       0, 1, 0, 1, 1, 0, 1, 1]))\n",
      "2017-04-17T06:48:05.928752: step 4, loss 1.83037, acc 0.65\n",
      "('predictions for this batch:', array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0]))\n",
      "2017-04-17T06:48:15.380511: step 5, loss 2.77858, acc 0.59\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 0, 0, 0, 1, 0]))\n",
      "2017-04-17T06:48:24.317314: step 6, loss 2.59351, acc 0.709677\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:48:26.402477: step 6, loss 1.9596, acc 0.8\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411646/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:48:36.460424: step 7, loss 2.15335, acc 0.77\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:48:45.974931: step 8, loss 1.86513, acc 0.79\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0]))\n",
      "2017-04-17T06:48:55.572581: step 9, loss 2.19738, acc 0.76\n",
      "('predictions for this batch:', array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:49:05.663488: step 10, loss 3.1912, acc 0.78\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:49:15.712725: step 11, loss 2.59141, acc 0.73\n",
      "('predictions for this batch:', array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:49:24.889025: step 12, loss 2.19172, acc 0.784946\n",
      "('predictions for this batch:', array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:49:27.066018: step 12, loss 1.80721, acc 0.8\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411646/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Subjectivity' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Positive Emotion\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Positive Emotion\n",
      "Vocabulary Size: 28958\n",
      "Train/Dev split: 593/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492411770\n",
      "\n",
      "2017-04-17T06:49:41.356118: step 1, loss 2.45198, acc 0.52\n",
      "('predictions for this batch:', array([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 1, 0]))\n",
      "2017-04-17T06:49:51.810026: step 2, loss 2.21355, acc 0.63\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:50:02.195617: step 3, loss 1.38038, acc 0.73\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 1, 0, 0]))\n",
      "2017-04-17T06:50:12.818899: step 4, loss 2.12798, acc 0.74\n",
      "('predictions for this batch:', array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:50:23.346222: step 5, loss 0.969935, acc 0.88\n",
      "('predictions for this batch:', array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:50:32.732361: step 6, loss 1.95139, acc 0.849462\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:50:34.840237: step 6, loss 1.70378, acc 0.861538\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411770/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:50:45.269951: step 7, loss 1.79173, acc 0.84\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:50:55.786588: step 8, loss 1.78715, acc 0.83\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:51:06.349932: step 9, loss 2.01022, acc 0.8\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:51:16.439563: step 10, loss 1.29805, acc 0.81\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0]))\n",
      "2017-04-17T06:51:26.344979: step 11, loss 2.01297, acc 0.72\n",
      "('predictions for this batch:', array([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:51:36.146809: step 12, loss 1.01515, acc 0.774194\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:51:38.235559: step 12, loss 0.764855, acc 0.861538\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411770/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Positive Emotion' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Negative Emotion\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Negative Emotion\n",
      "Vocabulary Size: 28915\n",
      "Train/Dev split: 591/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492411901\n",
      "\n",
      "2017-04-17T06:51:52.459752: step 1, loss 11.3199, acc 0.23\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:52:02.085280: step 2, loss 9.17796, acc 0.24\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:52:12.635405: step 3, loss 5.85656, acc 0.3\n",
      "('predictions for this batch:', array([1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:52:22.366641: step 4, loss 4.54486, acc 0.35\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1]))\n",
      "2017-04-17T06:52:32.670580: step 5, loss 3.09658, acc 0.52\n",
      "('predictions for this batch:', array([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 0, 0, 1, 1, 0, 1, 0]))\n",
      "2017-04-17T06:52:41.866400: step 6, loss 1.80879, acc 0.626374\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:52:43.959380: step 6, loss 1.56883, acc 0.784615\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411901/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:52:54.173754: step 7, loss 1.7831, acc 0.67\n",
      "('predictions for this batch:', array([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0]))\n",
      "2017-04-17T06:53:04.653143: step 8, loss 1.69609, acc 0.8\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:53:14.649978: step 9, loss 2.84485, acc 0.76\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:53:24.588003: step 10, loss 3.63473, acc 0.75\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:53:34.476105: step 11, loss 2.80537, acc 0.8\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "2017-04-17T06:53:44.124395: step 12, loss 3.49402, acc 0.747253\n",
      "('predictions for this batch:', array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:53:46.325898: step 12, loss 3.4459, acc 0.784615\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492411901/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Negative Emotion' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=100\n",
      "CHECKPOINT_EVERY=6\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=6\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LABEL_USED=Quality\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=2\n",
      "NUM_FILTERS=128\n",
      "UNROLLED_LSTM=False\n",
      "\n",
      "Loading data...\n",
      "Loaded rows:  658 columns:  19\n",
      "Headers:  ['id', 'news article name', 'news article', 'Fluency', 'Conciseness', 'Descriptiveness', 'Novelty', 'Completeness', 'Referencing', 'Formality', 'Richness', 'Attractiveness', 'Technicality', 'Popularity', 'Subjectivity', 'Positive Emotion', 'Negative Emotion', 'Quality', 'AnnotatorsConfidenceScore\\n']\n",
      "Using label:  Quality\n",
      "Vocabulary Size: 28906\n",
      "Train/Dev split: 591/65\n",
      "('Number of classes ', 2)\n",
      "Labels\n",
      "Tensor(\"accuracy/ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Predictions\n",
      "Tensor(\"output/predictions:0\", shape=(?,), dtype=int64)\n",
      "Writing to /notebooks/Project/runs/1492412029\n",
      "\n",
      "2017-04-17T06:54:02.727239: step 1, loss 2.32599, acc 0.61\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:54:13.689241: step 2, loss 2.26294, acc 0.61\n",
      "('predictions for this batch:', array([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 1, 1]))\n",
      "2017-04-17T06:54:24.083382: step 3, loss 2.12258, acc 0.55\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "       1, 0, 0, 0, 1, 0, 1, 1]))\n",
      "2017-04-17T06:54:34.016760: step 4, loss 2.12705, acc 0.57\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:54:43.916295: step 5, loss 1.39237, acc 0.65\n",
      "('predictions for this batch:', array([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 1]))\n",
      "2017-04-17T06:54:53.190836: step 6, loss 2.05717, acc 0.626374\n",
      "('predictions for this batch:', array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:54:55.493987: step 6, loss 1.68973, acc 0.707692\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492412029/checkpoints/model-6\n",
      "\n",
      "2017-04-17T06:55:06.753084: step 7, loss 1.82391, acc 0.7\n",
      "('predictions for this batch:', array([1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1]))\n",
      "2017-04-17T06:55:17.506060: step 8, loss 2.57486, acc 0.67\n",
      "('predictions for this batch:', array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1]))\n",
      "2017-04-17T06:55:27.853889: step 9, loss 1.74349, acc 0.66\n",
      "('predictions for this batch:', array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1]))\n",
      "2017-04-17T06:55:38.831586: step 10, loss 1.92132, acc 0.68\n",
      "('predictions for this batch:', array([1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1]))\n",
      "2017-04-17T06:55:49.532152: step 11, loss 1.45563, acc 0.66\n",
      "('predictions for this batch:', array([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "2017-04-17T06:55:58.845389: step 12, loss 1.41421, acc 0.637363\n",
      "('predictions for this batch:', array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]))\n",
      "\n",
      "Evaluation:\n",
      "2017-04-17T06:56:00.960265: step 12, loss 0.738088, acc 0.707692\n",
      "\n",
      "Saved model checkpoint to /notebooks/Project/runs/1492412029/checkpoints/model-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./shared_lib/train.py --label_used 'Quality' --num_epochs 2 --batch_size 100 --evaluate_every 6 --checkpoint_every 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pearsonr in module scipy.stats.stats:\n",
      "\n",
      "pearsonr(x, y)\n",
      "    Calculates a Pearson correlation coefficient and the p-value for testing\n",
      "    non-correlation.\n",
      "    \n",
      "    The Pearson correlation coefficient measures the linear relationship\n",
      "    between two datasets. Strictly speaking, Pearson's correlation requires\n",
      "    that each dataset be normally distributed, and not necessarily zero-mean.\n",
      "    Like other correlation coefficients, this one varies between -1 and +1\n",
      "    with 0 implying no correlation. Correlations of -1 or +1 imply an exact\n",
      "    linear relationship. Positive correlations imply that as x increases, so\n",
      "    does y. Negative correlations imply that as x increases, y decreases.\n",
      "    \n",
      "    The p-value roughly indicates the probability of an uncorrelated system\n",
      "    producing datasets that have a Pearson correlation at least as extreme\n",
      "    as the one computed from these datasets. The p-values are not entirely\n",
      "    reliable but are probably reasonable for datasets larger than 500 or so.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : (N,) array_like\n",
      "        Input\n",
      "    y : (N,) array_like\n",
      "        Input\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    r : float\n",
      "        Pearson's correlation coefficient\n",
      "    p-value : float\n",
      "        2-tailed p-value\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    http://www.statsoft.com/textbook/glosp.html#Pearson%20Correlation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydoc import help\n",
    "from scipy.stats.stats import pearsonr\n",
    "help(pearsonr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data from yahoo dataset\n",
    "def load_yahoo_data_labels(label_used):\n",
    "    header = []\n",
    "    articleData = []\n",
    "    with open('./news.csv', 'rb') as f:\n",
    "        for line in f:\n",
    "            if len(header) == 0:\n",
    "                header = line.split('\\t')\n",
    "            else:\n",
    "                articleData.append(line.split('\\t'))\n",
    "    columns = len(header)\n",
    "    rows = len(articleData)\n",
    "    \n",
    "    texts = []\n",
    "    targets = []\n",
    "    for i in range(0, rows):\n",
    "        labelStr = articleData[i][header.index(label_used)]\n",
    "        if labelStr != '':\n",
    "            texts.append(articleData[i][header.index('news article')])\n",
    "            target = int(labelStr)\n",
    "            targets.append(target)\n",
    "        else:\n",
    "            #add missing values \n",
    "            targets.append(3)\n",
    "    print 'Loaded rows: ', rows,'columns: ', columns, 'Using label: ', label_used, 'Targets length', len(targets)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows:  658 columns:  19 Using label:  Fluency Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Conciseness Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Descriptiveness Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Novelty Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Completeness Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Referencing Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Formality Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Richness Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Attractiveness Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Technicality Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Popularity Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Subjectivity Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Positive Emotion Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Negative Emotion Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Subjectivity Targets length 658\n",
      "Loaded rows:  658 columns:  19 Using label:  Quality Targets length 658\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "labels['Fluency'] = load_yahoo_data_labels('Fluency')\n",
    "labels['Conciseness'] = load_yahoo_data_labels('Conciseness')\n",
    "labels['Descriptiveness'] = load_yahoo_data_labels('Descriptiveness')\n",
    "labels['Novelty'] = load_yahoo_data_labels('Novelty')\n",
    "labels['Completeness'] = load_yahoo_data_labels('Completeness')\n",
    "labels['Referencing'] = load_yahoo_data_labels('Referencing')\n",
    "labels['Formality'] = load_yahoo_data_labels('Formality')\n",
    "labels['Richness'] = load_yahoo_data_labels('Richness')\n",
    "labels['Attractiveness'] = load_yahoo_data_labels('Attractiveness')\n",
    "labels['Technicality'] = load_yahoo_data_labels('Technicality')\n",
    "labels['Popularity'] = load_yahoo_data_labels('Popularity')\n",
    "labels['Subjectivity'] = load_yahoo_data_labels('Subjectivity')\n",
    "labels['PositiveEmotion'] = load_yahoo_data_labels('Positive Emotion')\n",
    "labels['NegativeEmotion'] = load_yahoo_data_labels('Negative Emotion')\n",
    "labels['Subjectivity'] = load_yahoo_data_labels('Subjectivity')\n",
    "\n",
    "label_Quality = load_yahoo_data_labels('Quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_Quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!rm label_correlation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52290621497476319, 1.8706453874907871e-47) Conciseness\n",
      "(0.4504620128899155, 3.3919295139596297e-34) Popularity\n",
      "(0.40972030174692514, 5.014242546156251e-28) Descriptiveness\n",
      "(0.51360938215499441, 1.4339657951881857e-45) Formality\n",
      "(0.6388017429647862, 9.8229297901455812e-77) Richness\n",
      "(0.51639238667890153, 3.9673074840509671e-46) Attractiveness\n",
      "(0.28955790778752516, 3.5535196358706179e-14) Technicality\n",
      "(0.44389282095785493, 3.826921942598057e-33) Novelty\n",
      "(0.21878079297127501, 1.4261452926210513e-08) Subjectivity\n",
      "(0.49269740336918144, 1.5454471309194023e-41) Referencing\n",
      "(0.70987994340442684, 6.0216610264496714e-102) Completeness\n",
      "(0.26764066523928798, 2.9504375912304476e-12) PositiveEmotion\n",
      "(0.68686129817758645, 5.4878902680671524e-93) Fluency\n",
      "(0.16832761209548577, 1.4205735551543075e-05) NegativeEmotion\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "ids = []\n",
    "correlation_coefficient = []\n",
    "pvalues = []\n",
    "\n",
    "myfile = open(\"label_correlation.csv\", 'wb')\n",
    "wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "wr.writerow(['featureId','correlation', 'log10_pvalue'])\n",
    "\n",
    "for i in labels:\n",
    "    p = pearsonr(labels[i], label_Quality)\n",
    "    print p, i\n",
    "    \n",
    "    ids.append(i)\n",
    "    correlation_coefficient.append(p[0])\n",
    "    pvalues.append( np.log10(p[1]))\n",
    "\n",
    "    wr.writerow([i,p[0], np.log10(p[1])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import Scatter, Figure, Layout\n",
    "from IPython.display import HTML\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "print __version__ # requires version >= 1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"d558318d-18fd-481c-9146-0097e6e79375\" style=\"height: 500px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"d558318d-18fd-481c-9146-0097e6e79375\", [{\"opacity\": 0.75, \"colorscale\": [[0, \"#00083e\"], [0.5, \"#ededee\"], [1, \"#ffffff\"]], \"showscale\": false, \"hoverinfo\": \"none\", \"z\": [[0, 0, 0], [0.5, 0.5, 0.5], [1, 1, 1], [0.5, 0.5, 0.5], [1, 1, 1], [0.5, 0.5, 0.5], [1, 1, 1], [0.5, 0.5, 0.5], [1, 1, 1], [0.5, 0.5, 0.5], [1, 1, 1], [0.5, 0.5, 0.5], [1, 1, 1], [0.5, 0.5, 0.5], [1, 1, 1]], \"type\": \"heatmap\"}], {\"yaxis\": {\"showticklabels\": false, \"tick0\": 0.5, \"ticks\": \"\", \"gridwidth\": 2, \"dtick\": 1, \"zeroline\": false, \"autorange\": \"reversed\"}, \"margin\": {\"r\": 0, \"b\": 0, \"l\": 0, \"t\": 0}, \"annotations\": [{\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"<b>featureId</b>\", \"align\": \"left\", \"y\": 0, \"x\": -0.45, \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"<b>correlation</b>\", \"align\": \"left\", \"y\": 0, \"x\": 0.55, \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"<b>log10_pvalue</b>\", \"align\": \"left\", \"y\": 0, \"x\": 1.55, \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Conciseness\", \"align\": \"left\", \"y\": 1, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.522906214975\", \"align\": \"left\", \"y\": 1, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-46.7280085326\", \"align\": \"left\", \"y\": 1, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Popularity\", \"align\": \"left\", \"y\": 2, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.45046201289\", \"align\": \"left\", \"y\": 2, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-33.4695531812\", \"align\": \"left\", \"y\": 2, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Descriptiveness\", \"align\": \"left\", \"y\": 3, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.409720301747\", \"align\": \"left\", \"y\": 3, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-27.2997946624\", \"align\": \"left\", \"y\": 3, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Formality\", \"align\": \"left\", \"y\": 4, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.513609382155\", \"align\": \"left\", \"y\": 4, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-44.8434612079\", \"align\": \"left\", \"y\": 4, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Richness\", \"align\": \"left\", \"y\": 5, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.638801742965\", \"align\": \"left\", \"y\": 5, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-76.0077589601\", \"align\": \"left\", \"y\": 5, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Attractiveness\", \"align\": \"left\", \"y\": 6, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.516392386679\", \"align\": \"left\", \"y\": 6, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-45.4015041385\", \"align\": \"left\", \"y\": 6, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Technicality\", \"align\": \"left\", \"y\": 7, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.289557907788\", \"align\": \"left\", \"y\": 7, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-13.4493412804\", \"align\": \"left\", \"y\": 7, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Novelty\", \"align\": \"left\", \"y\": 8, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.443892820958\", \"align\": \"left\", \"y\": 8, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-32.417150396\", \"align\": \"left\", \"y\": 8, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Subjectivity\", \"align\": \"left\", \"y\": 9, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.218780792971\", \"align\": \"left\", \"y\": 9, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-7.84583622724\", \"align\": \"left\", \"y\": 9, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Referencing\", \"align\": \"left\", \"y\": 10, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.492697403369\", \"align\": \"left\", \"y\": 10, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-40.8109458474\", \"align\": \"left\", \"y\": 10, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Completeness\", \"align\": \"left\", \"y\": 11, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.709879943404\", \"align\": \"left\", \"y\": 11, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-101.220283696\", \"align\": \"left\", \"y\": 11, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"PositiveEmotion\", \"align\": \"left\", \"y\": 12, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.267640665239\", \"align\": \"left\", \"y\": 12, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-11.5301135673\", \"align\": \"left\", \"y\": 12, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"Fluency\", \"align\": \"left\", \"y\": 13, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.686861298178\", \"align\": \"left\", \"y\": 13, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-92.2605945811\", \"align\": \"left\", \"y\": 13, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"NegativeEmotion\", \"align\": \"left\", \"y\": 14, \"x\": -0.45, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"0.168327612095\", \"align\": \"left\", \"y\": 14, \"x\": 0.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}, {\"xref\": \"x1\", \"xanchor\": \"left\", \"yref\": \"y1\", \"text\": \"-4.84753627425\", \"align\": \"left\", \"y\": 14, \"x\": 1.55, \"font\": {\"color\": \"#000000\"}, \"showarrow\": false}], \"xaxis\": {\"showticklabels\": false, \"tick0\": -0.5, \"ticks\": \"\", \"gridwidth\": 2, \"dtick\": 1, \"zeroline\": false}, \"height\": 500}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"64c4d88b-7c06-40b0-8513-235528891a33\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"64c4d88b-7c06-40b0-8513-235528891a33\", [{\"y\": [0.16832761209548575, 0.21878079297127487, 0.267640665239288, 0.2895579077875252, 0.409720301746925, 0.44389282095785504, 0.4504620128899156, 0.4926974033691813, 0.5136093821549944, 0.5163923866789014, 0.5229062149747632, 0.6388017429647862, 0.6868612981775866, 0.7098799434044267], \"x\": [\"NegativeEmotion\", \"Subjectivity\", \"PositiveEmotion\", \"Technicality\", \"Descriptiveness\", \"Novelty\", \"Popularity\", \"Referencing\", \"Formality\", \"Attractiveness\", \"Conciseness\", \"Richness\", \"Fluency\", \"Completeness\"], \"type\": \"bar\", \"name\": \"correlation\"}], {\"title\": \"correlation\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"1b85d769-6b35-4e48-9af4-65664c01bef5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1b85d769-6b35-4e48-9af4-65664c01bef5\", [{\"y\": [-4.847536274246153, -7.845836227240637, -11.530113567288627, -13.449341280411028, -27.29979466241817, -32.41715039595285, -33.469553181184345, -40.810945847373645, -44.843461207899864, -45.40150413845912, -46.728008532570705, -76.00775896008244, -92.2605945810567, -101.22028369559936], \"x\": [\"NegativeEmotion\", \"Subjectivity\", \"PositiveEmotion\", \"Technicality\", \"Descriptiveness\", \"Novelty\", \"Popularity\", \"Referencing\", \"Formality\", \"Attractiveness\", \"Conciseness\", \"Richness\", \"Fluency\", \"Completeness\"], \"type\": \"bar\", \"name\": \"log10_pvalue\"}], {\"title\": \"log10_pvalue\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "df = pd.read_csv(\"label_correlation.csv\")\n",
    "\n",
    "table = ff.create_table(df)\n",
    "\n",
    "df = df.sort_values(by='featureId')\n",
    "iplot(table)\n",
    "\n",
    "name = 'correlation'\n",
    "df = df.sort_values(by=name, ascending = True)\n",
    "data = go.Bar(x=df.featureId, y=df.correlation, name=name)\n",
    "layout = go.Layout(title=name)\n",
    "fig = go.Figure(data=[data], layout=layout)\n",
    "iplot(fig, filename=name)\n",
    "        \n",
    "name = 'log10_pvalue'\n",
    "df = df.sort_values(by=name, ascending = False)\n",
    "data = go.Bar(x=df.featureId, y=df.log10_pvalue, name=name)\n",
    "layout = go.Layout(title=name)\n",
    "fig = go.Figure(data=[data], layout=layout)\n",
    "iplot(fig, filename=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
